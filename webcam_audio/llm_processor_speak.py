# llm_processor.py
import os
import sys
import io
import asyncio
from transformers import AutoTokenizer
from optimum.intel.openvino import OVModelForCausalLM
from transformers.generation.streamers import TextStreamer

# edge-tts ìŒì„± ìŠ¤íŠ¸ë¦¬ë° ì¶œë ¥ìœ¼ë¡œ ìˆ˜ì •
from edge_tts import Communicate
from pydub import AudioSegment
import simpleaudio as sa
import asyncio

from AudioListener import AudioListener 


class LLMProcessor:
    def __init__(self, model_name="OpenVINO/Qwen2.5-1.5B-Instruct-fp16-ov"):
        self.model_name = model_name
        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)
        self.model = OVModelForCausalLM.from_pretrained(self.model_name)
        self.system_messages = [{
            "role": "system",
            "content": "ë‹¹ì‹ ì€ ITíšŒì‚¬ì—ì„œ ì‚¬ëŒì„ ë½‘ê¸°ìœ„í•´ ê³ ìš©ëœ ë©´ì ‘ê´€ ì…ë‹ˆë‹¤. ì‹œì‘ë˜ë©´ ì‚¬ìš©ìê°€ ë§í•˜ëŠ” 1ë¶„ ìê¸°ì†Œê°œë¥¼ ë“£ê³  íŒë‹¨í•´ì„œ ì—­ëŸ‰ê³¼ ì§ë¬´ì™€ ê´€ë ¨ëœ ì§ˆë¬¸ì„ í•˜ë‚˜ì”© í•˜ì„¸ìš”"  
        }]

    def get_response(self, user_input: str) -> str:
        self.system_messages.append({
            "role": "user",
            "content": user_input
        })

        # Qwen2.5 ì±„íŒ… í…œí”Œë¦¿ ì ìš©
        chat_prompt = self.tokenizer.apply_chat_template(
            self.system_messages,
            tokenize=False,
            add_generation_prompt=True
        )

        inputs = self.tokenizer(chat_prompt, return_tensors="pt", truncation=True, max_length=1024)

        # ìŠ¤íŠ¸ë¦¬ë¨¸ ì¶œë ¥ ìº¡ì²˜ ì„¤ì •
        old_stdout = sys.stdout
        redirected_output = io.StringIO()
        sys.stdout = redirected_output

        try:
            streamer = TextStreamer(self.tokenizer, skip_prompt=True)

            outputs = self.model.generate(
                **inputs,
                max_new_tokens=1024,
                temperature=0.7,
                top_p=0.9,
                do_sample=True,
                pad_token_id=self.tokenizer.eos_token_id,
                streamer=streamer
            )

            # ìŠ¤íŠ¸ë¦¬ë¨¸ë¡œ ì¶œë ¥ëœ í…ìŠ¤íŠ¸ ì¶”ì¶œ
            full_output_text = redirected_output.getvalue()

            # ëª¨ë¸ ì‘ë‹µì—ì„œ 'ì±—ë´‡:' ì´í›„ë§Œ ì¶”ì¶œ
            response = full_output_text.strip().split("ì±—ë´‡:")[-1].strip()

            # system_messagesì— ì±—ë´‡ ì‘ë‹µ ì¶”ê°€
            self.system_messages.append({
                "role": "assistant",
                "content": response
            })

            return response

        except Exception as e:
            print(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
            return "ì£„ì†¡í•©ë‹ˆë‹¤. ì‘ë‹µì„ ìƒì„±í•˜ëŠ” ë° ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
        finally:
            sys.stdout = old_stdout


    ### ğŸ—£ï¸ edge-tts ê¸°ë°˜ ì‹¤ì‹œê°„ TTS í•¨ìˆ˜ 
    async def speak_text(self, text: str) -> float:
        communicate = Communicate(text, voice="ko-KR-SunHiNeural")

        audio_buffer = bytearray()
        
        async for chunk in communicate.stream():
            if chunk["type"] == "audio":
                audio_buffer.extend(chunk["data"])

        audio_segment = AudioSegment.from_file(io.BytesIO(audio_buffer), format="mp3")

        duration_sec = audio_segment.duration_seconds

        playback = sa.play_buffer(
            audio_segment.raw_data,
            num_channels = audio_segment.channels,
            bytes_per_sample = audio_segment.sample_width,
            sample_rate = audio_segment.frame_rate
        )

        playback.wait_done()
        return duration_sec

    

    def run(self):
        print("AI ë©´ì ‘ê´€ì˜ ë©´ì ‘ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤. ë‚˜ê°€ë ¤ë©´ 'exit'ì„ ì…ë ¥í•˜ì„¸ìš”.")
        welcome_message = ",,ë°˜ê°‘ìŠµë‹ˆë‹¤ ì§€ì›ìë‹˜. ì €ëŠ” AIë©´ì ‘ê´€ ì˜¥ìˆœì…ë‹ˆë‹¤.ê° ëŒ€ë‹µì€ 10ì´ˆì•ˆì— ì§„í–‰í•´ì£¼ì„¸ìš”. ë¨¼ì €, ìê¸°ì˜ ê²½í—˜ê³¼ ì§ë¬´ì—­ëŸ‰ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”"

        asyncio.run(self.speak_text(welcome_message))
        
        audio_listener = AudioListener()

        while True:
            print("ì‚¬ìš©ìì˜ ë‹µë³€ ì°¨ë¡€")
            user_input = audio_listener.start()
            
            # êº¼ì§€ì§€ ì•Šì€ ë¬¸ì œ 
            if user_input.strip().lower() == "ë©´ì ‘ì¢…ë£Œ":
                print("ì±„íŒ… ì¢…ë£Œ")
                break

            response = self.get_response(user_input)
            print(f"ë©´ì ‘ê´€: {response}")

            # ìŒì„± ì¶œë ¥ (ë¹„ë™ê¸° ì‹¤í–‰)
            response_duration = asyncio.run(self.speak_text(response))    
            print(f"response_duration is {response_duration}")
            # ìŒì„± ì¶œë ¥ ì‹œê°„ ì§€ì—°ì´ ë”±íˆ í•„ìš”ì—†ìŒ 
            #asyncio.run(asyncio.sleep(response_duration))


### âœ… ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    llm = LLMProcessor()
    llm.run()
